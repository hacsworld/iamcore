# core/app.py
from fastapi import FastAPI, UploadFile, File, Form
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
import numpy as np
import uvicorn
from typing import List, Dict, Any, Optional
import os, pathlib, time

app = FastAPI(title="HACS Core (Local)", version="2.4")

# ===== Embedding model (multilingual) =====
# ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ 50+ ÑÐ·Ñ‹ÐºÐ¾Ð²: Ð¾Ð´Ð¸Ð½ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð²ÑÐµÑ…
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# ===== Built-in simple KB =====
KNOWLEDGE_BASE = [
    {"text": "Open settings and configure preferences"},
    {"text": "Create a new note or document"},
    {"text": "Pay invoices and manage billing"},
    {"text": "Control smart home devices and lights"},
    {"text": "Schedule appointments and meetings"},
    {"text": "Search the web for information"},
    {"text": "Play music and control playback"},
    {"text": "Set reminders and timers"},
    {"text": "Send messages and emails"},
    {"text": "Translate languages in real-time"}
]
knowledge_embeddings = np.array([model.encode(item["text"]) for item in KNOWLEDGE_BASE])

# ===== Resonance Memory =====
try:
    from .self_learn import ResonanceMemory
except ImportError:
    from self_learn import ResonanceMemory

MEMORY = ResonanceMemory(dim=knowledge_embeddings.shape[1], k=8, save_every=5)

# ===== Readers (files â†’ text) =====
try:
    from .readers import sniff_and_read
except Exception:
    from readers import sniff_and_read

# ===== Utils =====
def cosine_similarity(query_embedding, knowledge_embeddings):
    qn = query_embedding / (np.linalg.norm(query_embedding) + 1e-9)
    kn = knowledge_embeddings / (np.linalg.norm(knowledge_embeddings, axis=1, keepdims=True) + 1e-9)
    return np.dot(kn, qn)

def _ingest_text_payload(filename: str, raw_text: str, tag: str) -> Dict[str, Any]:
    """
    Ð ÐµÐ¶ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ‡Ð°Ð½ÐºÐ¸ Ð¸ ÐºÐ»Ð°Ð´Ñ‘Ð¼ Ð² Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½ÑƒÑŽ Ð¿Ð°Ð¼ÑÑ‚ÑŒ.
    Ð‘ÐµÐ· Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð² Ð½Ð° ÑÐ¼Ñ‹ÑÐ», Ð½Ð¾ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð²Ð·Ð¾Ñ€Ð²Ð°Ñ‚ÑŒ RAM, Ð´ÐµÐ»Ð°ÐµÐ¼ Ñ€Ð°Ð·ÑƒÐ¼Ð½Ñ‹Ð¹ ÑˆÐ°Ð³.
    ÐŸÑ€Ð¸ Ð¶ÐµÐ»Ð°Ð½Ð¸Ð¸ Ð¼Ð¾Ð¶ÐµÑˆÑŒ ÑƒÐ±Ñ€Ð°Ñ‚ÑŒ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ limit.
    """
    raw = (raw_text or "").strip()
    if not raw:
        return {"filename": filename, "ingested_chunks": 0, "approx_chars": 0}

    step = 1500
    limit = max(len(raw), 1500)  # Ð¿Ð¾ ÑÑƒÑ‚Ð¸ â€” Ð²ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚
    ingested = 0

    for i in range(0, min(len(raw), limit), step):
        ch = raw[i:i+step]
        emb = model.encode(ch)
        score = min(0.99, 0.5 + len(ch) / 5000.0)
        MEMORY.learn(f"[{tag}] {filename}: {ch[:120]}", emb, score)
        ingested += 1

    return {"filename": filename, "ingested_chunks": ingested, "approx_chars": len(raw)}

# ===== Classic intent endpoint (/act) =====
class IntentRequest(BaseModel):
    text: str

@app.post("/act")
async def process_intent(request: IntentRequest):
    try:
        q_emb = model.encode(request.text)
        sims = cosine_similarity(q_emb, knowledge_embeddings)
        top_indices = np.argsort(sims)[-3:][::-1]

        results = [{"text": KNOWLEDGE_BASE[i]["text"], "similarity": float(sims[i])} for i in top_indices]
        best = float(sims[top_indices[0]]) if len(top_indices) else 0.0
        status = "EXECUTE" if best > 0.6 else "REFINE"

        MEMORY.learn(request.text, q_emb, best)

        return {
            "status": status,
            "resonance": {
                "purity": best,
                "decay": float(1.0 - best),
                "gain": 0.9,
                "strength": float(best * 0.9),
            },
            "context": results,
            "local": True,
        }
    except Exception as e:
        return {"status": "ERROR", "error": str(e), "local": True}

# ===== Health & memory =====
@app.get("/health")
async def health_check():
    return {"status": "OK", "service": "HACS Local Core", "version": "2.4",
            "model": "paraphrase-multilingual-MiniLM-L12-v2"}

@app.get("/memory/stats")
async def memory_stats():
    return MEMORY.stats()

# ===== Multilingual chat (/chat) =====
# Ð¯Ð·Ñ‹Ðº Ð²Ñ…Ð¾Ð´Ð° â†’ Ð´ÐµÑ‚ÐµÐºÑ‚, Ð¾Ñ‚Ð²ÐµÑ‚ â†’ ÑÐ·Ñ‹Ðº Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ (Ð¸Ð»Ð¸ target_lang)
from langdetect import detect, DetectorFactory
DetectorFactory.seed = 42

# ÐžÑ„Ñ„Ð»Ð°Ð¹Ð½-Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
_HAS_ARGOS = False
try:
    import argostranslate.package as argos_pkg
    import argostranslate.translate as argos_tr
    _HAS_ARGOS = True
except Exception:
    _HAS_ARGOS = False

def _ensure_argos_pair(src: str, tgt: str):
    if not _HAS_ARGOS:
        return
    try:
        pairs = argos_tr.get_installed_languages()
        for L in pairs:
            if L.code == src:
                for to in L.translation_languages:
                    if to.code == tgt:
                        return
        available = argos_pkg.get_available_packages()
        for p in available:
            if p.from_code == src and p.to_code == tgt:
                argos_pkg.install_from_path(p.download())
                break
    except Exception:
        pass

def _translate(text: str, src: str, tgt: str) -> str:
    if not _HAS_ARGOS or src == tgt or not text.strip():
        return text
    try:
        _ensure_argos_pair(src, tgt)
        langs = argos_tr.get_installed_languages()
        Lsrc = next((L for L in langs if L.code == src), None)
        if not Lsrc:
            return text
        translator = next((t for t in Lsrc.translation_languages if t.code == tgt), None)
        if not translator:
            return text
        return translator.translate(text)
    except Exception:
        return text

# ÐšÐ°Ñ‚Ð°Ð»Ð¾Ð³ ÐºÐ¾Ð¼Ð°Ð½Ð´ (Ð¸Ð½Ñ‚ÐµÐ½Ñ‚Ñ‹) â€” Ð´Ð»Ñ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹
COMMANDS = [
    {"id": "open_settings", "text": "Open settings and configure preferences"},
    {"id": "create_note", "text": "Create a new note or document"},
    {"id": "pay_billing", "text": "Pay invoices and manage billing"},
    {"id": "control_smart_home", "text": "Control smart home devices and lights"},
    {"id": "schedule_meeting", "text": "Schedule appointments and meetings"},
    {"id": "web_search", "text": "Search the web for information"},
    {"id": "play_music", "text": "Play music and control playback"},
    {"id": "set_reminder", "text": "Set reminders and timers"},
    {"id": "send_message", "text": "Send messages and emails"},
    {"id": "translate_rt", "text": "Translate languages in real time"},
]
_command_embeddings = np.array([model.encode(c["text"]) for c in COMMANDS])

def _top_command(query: str):
    q = model.encode(query)
    qn = q / (np.linalg.norm(q) + 1e-9)
    kn = _command_embeddings / (np.linalg.norm(_command_embeddings, axis=1, keepdims=True) + 1e-9)
    sims = np.dot(kn, qn)
    idx = int(np.argmax(sims))
    return COMMANDS[idx], float(sims[idx]), q

class ChatRequest(BaseModel):
    text: str
    target_lang: Optional[str] = None

@app.post("/chat")
async def chat(req: ChatRequest):
    try:
        # Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¹ ÑÐ·Ñ‹Ðº
        try:
            src_lang = (detect(req.text) or "en").split("-")[0]
        except Exception:
            src_lang = "en"

        # Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÐ¸Ð¹ Ð¸Ð½Ñ‚ÐµÐ½Ñ‚ Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        cmd, score, q_emb = _top_command(req.text)

        # Ñ‚Ð¾Ð¿-3 Ð¸Ð· KB
        sims_kb = np.dot(
            knowledge_embeddings / (np.linalg.norm(knowledge_embeddings, axis=1, keepdims=True) + 1e-9),
            q_emb / (np.linalg.norm(q_emb) + 1e-9)
        )
        top_kb_idx = np.argsort(sims_kb)[-3:][::-1]
        kb_hits = [{"text": KNOWLEDGE_BASE[i]["text"], "similarity": float(sims_kb[i])} for i in top_kb_idx]

        # Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð¿Ð°Ð¼ÑÑ‚Ð¸, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
        memory_hits = []
        try:
            if hasattr(MEMORY, "search"):
                for r in MEMORY.search(q_emb, k=5):
                    memory_hits.append({
                        "label": r.get("label") or r.get("text") or "",
                        "score": float(r.get("score", 0.0))
                    })
        except Exception:
            pass

        # Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ (Ð°Ð½Ð³Ð»), Ð·Ð°Ñ‚ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ð¼
        answer_en = (
            f"Intent: {cmd['id']} (score={score:.2f}).\n"
            f"I understood your request and can act accordingly.\n"
            f"Closest knowledge:\n- " + "\n- ".join(h['text'] for h in kb_hits)
        )
        tgt_lang = (req.target_lang or src_lang or "en").split("-")[0]
        answer_out = _translate(answer_en, "en", tgt_lang)

        # ÑƒÑ‡Ð¸Ð¼ÑÑ Ð½Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸
        MEMORY.learn(req.text, q_emb, max(0.0, min(1.0, score)))

        return {
            "status": "OK",
            "lang_in": src_lang,
            "lang_out": tgt_lang,
            "intent": {"id": cmd["id"], "score": score},
            "answer": answer_out,
            "kb": kb_hits,
            "memory_hits": memory_hits,
            "local": True,
        }
    except Exception as e:
        return {"status": "ERROR", "error": str(e), "local": True}

# ===== Ingest endpoints =====
@app.post("/ingest")
async def ingest_file(file: UploadFile = File(...), tag: str = Form(default="generic")):
    data = await file.read()
    kind, text = sniff_and_read(file.filename, data)
    if not (text or "").strip():
        return {"status": "EMPTY", "kind": kind, "bytes": len(data), "filename": file.filename}
    res = _ingest_text_payload(file.filename, text, tag)
    return {"status": "OK", "kind": kind, **res}

@app.post("/ingest/batch")
async def ingest_batch(files: List[UploadFile] = File(...), tag: str = Form(default="generic")):
    results = []
    for f in files:
        data = await f.read()
        kind, text = sniff_and_read(f.filename, data)
        if not (text or "").strip():
            results.append({"filename": f.filename, "kind": kind, "ingested_chunks": 0, "approx_chars": 0})
            continue
        res = _ingest_text_payload(f.filename, text, tag)
        results.append({"kind": kind, **res})
    return {"status": "OK", "files": results}

@app.post("/ingest/url")
async def ingest_url(url: str = Form(...), tag: str = Form(default="generic")):
    import urllib.request
    from urllib.parse import urlparse
    try:
        with urllib.request.urlopen(url, timeout=20) as resp:
            data = resp.read()
            name = os.path.basename(urlparse(url).path) or "remote.bin"
    except Exception as e:
        return {"status": "ERROR", "error": str(e), "url": url}

    kind, text = sniff_and_read(name, data)
    if not (text or "").strip():
        return {"status": "EMPTY", "kind": kind, "bytes": len(data), "filename": name}
    res = _ingest_text_payload(name, text, tag)
    return {"status": "OK", "kind": kind, **res}

# ===== Auto-scan helpers & endpoints =====
AUTO_PATHS = [
    pathlib.Path.home() / "Documents",
    pathlib.Path.home() / "Downloads",
    pathlib.Path.home() / "Pictures",
    pathlib.Path.home() / "Desktop",
]
INDEX_CACHE: Dict[str, tuple[int, float]] = {}  # path -> (size, mtime)

def _should_ingest(path: pathlib.Path) -> bool:
    try:
        st = path.stat()
        key = str(path.resolve())
        cur = (st.st_size, st.st_mtime)
        prev = INDEX_CACHE.get(key)
        if prev == cur:
            return False
        INDEX_CACHE[key] = cur
        return True
    except Exception:
        return False

def _iter_files(base: pathlib.Path, recursive: bool) -> List[pathlib.Path]:
    if not base.exists() or not base.is_dir():
        return []
    return [p for p in (base.rglob("*") if recursive else base.iterdir()) if p.is_file()]

def _scan_one_file(fpath: pathlib.Path, tag: str) -> Dict[str, Any]:
    try:
        data = fpath.read_bytes()
        kind, text = sniff_and_read(fpath.name, data)
        if not (text or "").strip():
            return {"filename": str(fpath), "kind": kind, "ingested_chunks": 0, "approx_chars": 0}
        res = _ingest_text_payload(fpath.name, text, tag)
        return {"filename": str(fpath), "kind": kind, **res}
    except Exception as e:
        return {"filename": str(fpath), "error": str(e), "kind": "unknown", "ingested_chunks": 0, "approx_chars": 0}

@app.on_event("startup")
async def auto_bootstrap():
    print("ðŸ“‚ Scanning local storage for files...")
    for base in AUTO_PATHS:
        if not base.exists():
            continue
        for f in _iter_files(base, recursive=True):
            if not _should_ingest(f):
                continue
            r = _scan_one_file(f, tag="auto")
            if r.get("ingested_chunks", 0) > 0:
                print(f"  [+] Ingested {f}")
    print("âœ… Bootstrap complete.")

@app.post("/ingest/scan")
async def ingest_scan(
    path: str = Form(default=""),       # Ð¿ÑƒÑÑ‚Ð¾ â†’ AUTO_PATHS
    tag: str = Form(default="auto"),
    recursive: bool = Form(default=True)
):
    started = time.time()
    if path.strip():
        base = pathlib.Path(path).expanduser()
        if not base.exists() or not base.is_dir():
            return {"status": "ERROR", "error": f"Path not found or not a directory: {base}"}
        bases = [base]
    else:
        bases = [p for p in AUTO_PATHS if p.exists()]

    scanned_files = 0
    processed: List[Dict[str, Any]] = []
    for base in bases:
        for f in _iter_files(base, recursive=recursive):
            scanned_files += 1
            if not _should_ingest(f):
                continue
            processed.append(_scan_one_file(f, tag))

    took = round(time.time() - started, 3)
    ingested = sum(1 for r in processed if r.get("ingested_chunks", 0) > 0)
    errors = [r for r in processed if "error" in r]

    return {
        "status": "OK",
        "scanned_dirs": [str(b) for b in bases],
        "scanned_files": scanned_files,
        "ingested_files": ingested,
        "errors": len(errors),
        "took_sec": took,
        "details": processed[:100],  # Ð¼Ð¾Ð¶Ð½Ð¾ ÑƒÐ±Ñ€Ð°Ñ‚ÑŒ Ð»Ð¸Ð¼Ð¸Ñ‚
    }

@app.get("/ingest/autopaths")
async def list_autopaths():
    present = [str(p) for p in AUTO_PATHS if p.exists()]
    missing = [str(p) for p in AUTO_PATHS if not p.exists()]
    return {"present": present, "missing": missing}

# ===== Entrypoint =====
if __name__ == "__main__":
    print("ðŸš€ Starting HACS Local Core on http://127.0.0.1:8000")
    uvicorn.run(app, host="127.0.0.1", port=8000, log_level="info")
